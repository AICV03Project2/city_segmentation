import os
import cv2
import asyncio
import numpy as np
import torch
import base64
import uvicorn
import nest_asyncio
from contextlib import asynccontextmanager
from fastapi import FastAPI, Request
from fastapi.responses import FileResponse, JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import Dict, Any
from datetime import datetime
from ultralytics import YOLO
from concurrent.futures import ThreadPoolExecutor

# =========================
# 1) ì„¤ì • ë° ì´ˆê¸°í™”
# =========================
YOLO_PT_PATH = "/content/drive/MyDrive/Colab_Notebooks/Segmentation_pro/model_save/best_v8m.pt"
MASK_BASE_PATH = "/content/drive/MyDrive/Colab_Notebooks/Segmentation_pro/road_mask"
FRONT_ABS_PATH = "/content/drive/MyDrive/Colab_Notebooks/Segmentation_pro/web_site/front"

DEVICE = "cuda:0"
IMG_SIZE = 640       # A100ì˜ ê²½ìš° 640ì´ ì†ë„ì™€ ì •í™•ë„ì˜ ìµœì  ì§€ì ì…ë‹ˆë‹¤.
JPEG_QUALITY = 65    # CPU ë¶€í•˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ í’ˆì§ˆì„ 65ë¡œ ìµœì í™”
USE_HALF = True      # A100(FP16 ê°€ì†) ì‚¬ìš© í•„ìˆ˜

# ì „ì—­ ìƒíƒœ ê´€ë¦¬
cached_urls = {}
latest_results = {}
preloaded_masks_gpu = {}

# [ë³‘ë ¬í™”] A100ì˜ ìì›ì„ í™œìš©í•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ ì¸ì½”ë”© ì „ìš© ì“°ë ˆë“œ í’€ í™•ì¥
thread_executor = ThreadPoolExecutor(max_workers=24)

print(f"ğŸš€ A100 GPU ê°€ì† ëª¨ë“œ ê°€ë™ ì¤‘ (imgsz: {IMG_SIZE})...")
model = YOLO(YOLO_PT_PATH)
model.to(DEVICE)
if USE_HALF:
    model.half()  # ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ FP16ìœ¼ë¡œ ê³ ì •

# =========================
# 2) ìˆ˜ëª… ì£¼ê¸° ê´€ë¦¬ (Lifespan)
# =========================
@asynccontextmanager
async def lifespan(app: FastAPI):
    # í¬íŠ¸ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ì‹¤í–‰ ì „ ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ê¶Œì¥: !fuser -k 8000/tcp
    prepare_gpu_masks()
    # ë¶„ì„ ì—”ì§„ì„ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ë¶„ë¦¬
    analysis_task = asyncio.create_task(global_analysis_engine())
    yield
    analysis_task.cancel()
    thread_executor.shutdown(wait=False)

app = FastAPI(lifespan=lifespan)
nest_asyncio.apply()

def prepare_gpu_masks():
    """ë§ˆìŠ¤í¬ë¥¼ FP16 íƒ€ì…ìœ¼ë¡œ GPUì— ë¯¸ë¦¬ ë¡œë“œí•˜ì—¬ ì—°ì‚° ì†ë„ ê·¹ëŒ€í™”"""
    global preloaded_masks_gpu
    if not os.path.exists(MASK_BASE_PATH): return
    for i in range(1, 7):
        for direct in ['up', 'low']:
            path = f"{MASK_BASE_PATH}/{i}_{direct}.png"
            if os.path.exists(path):
                mask_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
                mask_img = cv2.resize(mask_img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
                
                # [ì—ëŸ¬ ë°©ì§€] ë¡œë“œ ë‹¨ê³„ë¶€í„° Half(FP16)ë¡œ ê°•ì œ ë³€í™˜
                mask_tensor = torch.from_numpy(mask_img).to(DEVICE).half() / 255.0
                preloaded_masks_gpu[f"{i}_{direct}"] = (mask_tensor > 0.5).to(dtype=torch.float16)
    print(f"âœ… {len(preloaded_masks_gpu)}ê°œ ROI ë§ˆìŠ¤í¬ FP16 ì¤€ë¹„ ì™„ë£Œ")

# =========================
# 3) ë¹„ë™ê¸° ì´ë¯¸ì§€ ì²˜ë¦¬ (CPU ë³‘ëª© ë¶„ì‚°)
# =========================
def process_and_update(res, cid, final_data):
    """ë³„ë„ ì“°ë ˆë“œì—ì„œ ì´ë¯¸ì§€ ì‹œê°í™” ë° JPEG ì¸ì½”ë”© ìˆ˜í–‰"""
    try:
        # 1. ì‹œê°í™” (CPU)
        annotated = res.plot(boxes=False, masks=True)
        # 2. JPEG ì••ì¶• (ê°€ì¥ ë¬´ê±°ìš´ ì‘ì—…)
        _, buffer = cv2.imencode('.jpg', annotated, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
        img_str = base64.b64encode(buffer).decode('utf-8')
        
        # 3. ìµœì‹  ê²°ê³¼ ì—…ë°ì´íŠ¸
        latest_results[cid] = {
            "channel_id": cid,
            "vehicle_total_count": len(res.boxes) if res.boxes is not None else 0,
            "results": final_data,
            "encoded_image": img_str,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        pass # ì¸ì½”ë”© ë„ì¤‘ ë°œìƒí•˜ëŠ” ì‚¬ì†Œí•œ ì—ëŸ¬ ë¬´ì‹œ

# =========================
# 4) í†µí•© ë¶„ì„ ì—”ì§„ (GPU ë°°ì¹˜ ì¶”ë¡ )
# =========================

async def global_analysis_engine():
    caps = {}
    while True:
        if not cached_urls:
            await asyncio.sleep(0.5)
            continue

        cids = list(cached_urls.keys())
        batch_frames = []
        active_cids = []

        # 1. í”„ë ˆì„ ìº¡ì²˜ ë° ì „ì²˜ë¦¬ (Resize)
        for cid in cids:
            if cid not in caps:
                caps[cid] = cv2.VideoCapture(cached_urls[cid])
                caps[cid].set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            if caps[cid].grab():
                success, frame = caps[cid].retrieve()
                if success:
                    batch_frames.append(cv2.resize(frame, (IMG_SIZE, IMG_SIZE)))
                    active_cids.append(cid)

        if not batch_frames:
            await asyncio.sleep(0.01)
            continue

        try:
            # 2. GPU Batch Inference (A100ì˜ ë³‘ë ¬ ì—°ì‚° í™œìš©)
            results = model.predict(
                source=batch_frames, 
                imgsz=IMG_SIZE, 
                device=DEVICE, 
                half=USE_HALF, 
                verbose=False
            )

            # 3. ê²°ê³¼ ë¶„ì„ ë° ì“°ë ˆë“œ ìœ„ì„
            for i, res in enumerate(results):
                cid = active_cids[i]
                final_data = {}

                if res.masks is not None:
                    # [ì—ëŸ¬ ë°©ì§€ í•µì‹¬] ëª¨ë“  í…ì„œ ì—°ì‚° ì§ì „ì— FP16ìœ¼ë¡œ ê°•ì œ ìºìŠ¤íŒ…
                    pred_masks = res.masks.data.to(dtype=torch.float16)
                    combined_mask = torch.any(pred_masks > 0.5, dim=0).to(dtype=torch.float16)
                    
                    for direct in ['up', 'low']:
                        m_key = f"{cid}_{direct}"
                        if m_key in preloaded_masks_gpu:
                            roi = preloaded_masks_gpu[m_key].to(dtype=torch.float16)
                            
                            # í…ì„œ ì—°ì‚°ì„ í†µí•œ ì ìœ ìœ¨ ê³„ì‚°
                            overlap = (combined_mask * roi).sum().item()
                            roi_area = roi.sum().item()
                            occ_rate = overlap / (roi_area + 1e-6)
                            
                            final_data[direct] = {
                                "occupancy_rate": round(occ_rate * 100, 1),
                                "status": "ì›í™œ" if occ_rate < 0.25 else "ì •ì²´" if occ_rate > 0.5 else "ì„œí–‰"
                            }

                # 4. ë¬´ê±°ìš´ ì¸ì½”ë”© ì‘ì—…ì€ ì“°ë ˆë“œ í’€ë¡œ ì „ë‹¬ (Fire-and-Forget)
                thread_executor.submit(process_and_update, res, cid, final_data)

        except Exception as e:
            print(f"âš ï¸ ë¶„ì„ ë£¨í”„ ì˜¤ë¥˜: {e}")
        
        await asyncio.sleep(0) # ì¦‰ì‹œ ë‹¤ìŒ ë£¨í”„ ì‹¤í–‰

# =========================
# 5) API ì—”ë“œí¬ì¸íŠ¸
# =========================
class URLUpdate(BaseModel):
    urls: Dict[str, str]

@app.post("/update_urls")
async def update_urls(data: URLUpdate):
    global cached_urls
    cached_urls = {int(k): v for k, v in data.urls.items()}
    return {"status": "success"}

@app.get("/api/v1/traffic/{channel_id}")
async def get_traffic_data(channel_id: int):
    data = latest_results.get(channel_id)
    if not data: return JSONResponse(content={"error": "no data"}, status_code=503)
    res_only = data.copy()
    if "encoded_image" in res_only: del res_only["encoded_image"]
    return res_only

@app.get("/video_feed/{channel_id}")
async def video_feed(channel_id: int):
    async def frame_generator():
        while True:
            data = latest_results.get(channel_id)
            if data and "encoded_image" in data:
                img_data = base64.b64decode(data["encoded_image"])
                yield (b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + img_data + b'\r\n')
            await asyncio.sleep(0.04) # ì•½ 25 FPS
    return StreamingResponse(frame_generator(), media_type="multipart/x-mixed-replace; boundary=frame")

@app.get("/")
async def read_index():
    index_path = os.path.join(FRONT_ABS_PATH, "index.html")
    if os.path.exists(index_path): return FileResponse(index_path)
    return JSONResponse(content={"error": "index.html not found"}, status_code=404)

if os.path.exists(FRONT_ABS_PATH):
    app.mount("/front", StaticFiles(directory=FRONT_ABS_PATH), name="front")

if __name__ == "__main__":
    # ì‹¤í–‰ ì „ ë°˜ë“œì‹œ !fuser -k 8000/tcp ì‹¤í–‰í•˜ì—¬ í¬íŠ¸ë¥¼ ë¹„ì›Œì£¼ì„¸ìš”.
    uvicorn.run(app, host="0.0.0.0", port=8000, access_log=False)